{
  "results": {
    "hellaswag": {
      "acc": 0.59699263095001,
      "acc_stderr": 0.004894997736719055,
      "acc_norm": 0.7947619996016729,
      "acc_norm_stderr": 0.004030500234129676
    },
    "lambada_openai": {
      "ppl": 3.403726992801658,
      "ppl_stderr": 0.07281515136684007,
      "acc": 0.7259848631864934,
      "acc_stderr": 0.006213883873801305
    },
    "piqa": {
      "acc": 0.8019586507072906,
      "acc_stderr": 0.009298209954776726,
      "acc_norm": 0.8150163220892275,
      "acc_norm_stderr": 0.009059313316508666
    },
    "winogrande": {
      "acc": 0.7348066298342542,
      "acc_stderr": 0.01240654946619286
    }
  },
  "versions": {
    "hellaswag": 0,
    "lambada_openai": 0,
    "piqa": 0,
    "winogrande": 0
  },
  "args": {
    "buckets": [
      16,
      32,
      64,
      128,
      189,
      284,
      384
    ],
    "output_file": "./logs/llama-3.1-8b/eval/fp8_measure.json",
    "tasks": [
      "hellaswag",
      "lambada_openai",
      "piqa",
      "winogrande"
    ],
    "limit_iters": null,
    "device": "hpu",
    "model_name_or_path": "/model_weights/meta-llama/Llama-3.1-8B-Instruct/",
    "bf16": true,
    "max_new_tokens": 100,
    "max_input_tokens": 0,
    "batch_size": 1,
    "warmup": 3,
    "n_iterations": 5,
    "local_rank": 0,
    "use_kv_cache": true,
    "use_hpu_graphs": true,
    "dataset_name": null,
    "column_name": null,
    "do_sample": false,
    "num_beams": 1,
    "top_k": null,
    "penalty_alpha": null,
    "trim_logits": false,
    "seed": 27,
    "profiling_warmup_steps": 0,
    "profiling_steps": 0,
    "profiling_record_shapes": false,
    "prompt": null,
    "bad_words": null,
    "force_words": null,
    "assistant_model": null,
    "peft_model": null,
    "num_return_sequences": 1,
    "token": null,
    "model_revision": "main",
    "attn_softmax_bf16": false,
    "output_dir": null,
    "bucket_size": -1,
    "bucket_internal": false,
    "dataset_max_samples": -1,
    "limit_hpu_graphs": false,
    "show_graphs_count": false,
    "reuse_cache": false,
    "verbose_workers": false,
    "simulate_dyn_prompt": null,
    "reduce_recompile": false,
    "use_chat_template": false,
    "use_flash_attention": true,
    "flash_attention_recompute": false,
    "flash_attention_causal_mask": false,
    "flash_attention_fast_softmax": true,
    "book_source": false,
    "torch_compile": false,
    "ignore_eos": true,
    "temperature": 1.0,
    "top_p": 1.0,
    "const_serialization_path": null,
    "trust_remote_code": false,
    "parallel_strategy": "none",
    "input_embeds": false,
    "run_partial_dataset": false,
    "load_quantized_model_with_autogptq": false,
    "disk_offload": false,
    "load_quantized_model_with_inc": false,
    "local_quantized_inc_model_path": null,
    "quant_config": "./quantization_config/maxabs_measure.json",
    "world_size": 0,
    "global_rank": 0
  },
  "duration": 1113.9754724986851
}